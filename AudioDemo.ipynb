{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Creating Digital Audio</h1>\n",
    "\n",
    "With Python, we can create, record, and manipulate audio with just a few lines of code. After going through this notebook, you'll understand some of the basics of digital audio, and how we can interact with audio through code. Also, you'll see how powerful Python is, especially if we use some of the many available libraries.\n",
    "\n",
    "A basic building block of audio is a sine tone. Actually, all sounds we hear can be modeled as a sum of different sine tones. So let's begin by creating a sine wave, listening to it, and looking at with different visualizations.\n",
    "\n",
    "The main characteristic of a sine tone is it's _frequency_. The frequency sets the pitch of the sound - how high or low it sounds. The range of frequencies for human hearing is 20-20,000 Hz. What's a good frequency for our sine tone that's not too high or too low?\n",
    "\n",
    "Think of an orchestra or symphony tuning together at the start of a performance. This is a fairly pleasing frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Audio, display, clear_output\n",
    "%matplotlib inline\n",
    "HTML('<iframe width=\"800\" height=\"600\" src=\"https://www.youtube.com/embed/KfSH1ezevjM?rel=0\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tone they're tuning to is \"A 440\". It's the note A, at 440 _Hertz_. We can generate a digital version of this tone with a few lines of Python.\n",
    "\n",
    "A tone is just a sine wave, following the formula\n",
    "\n",
    "$$\n",
    "wave = \\sin(2 * pi * frequency * time)\n",
    "$$\n",
    "\n",
    "For digital audio, we generate samples at even time steps. Samples are the smallest unit of a digital audio wave, similar to how a pixel is the smallest unit in a digital image.  We need to set a sampling rate, or how often to create digital samples.\n",
    "\n",
    "This image shows an example of a digital audio signal. The red line is the original audio, and the blue dots are the digital representation. Sampling rate is how often to generate those blue dots.\n",
    "![Digital Audio](img/samples.svg)\n",
    "\n",
    "Let's set the sampling rate to 48,000 samples per second (also known as _Hertz_ or Hz), fast enough to capture all sounds in the range of human hearing. We could generate other very low or high pitches with this sampling rate.\n",
    "\n",
    "The lines of code below set up some variables with our parameters, like the tone's frequency (440 Hz to match the orchestra sound), duration, and sample rate. The sample rate is used to generate a timeline, $t$. It will be a list of numbers representing the clock time for each sample. It starts at time zero, the next number is $T$, then $2*T$, $3*T$, and so on.\n",
    "\n",
    "To help us make this list, we import numpy, which is a Python library useful for manipulating numbers, vectors, and matrices in Python. numpy makes this timeline for us automatically, if we give it the start value, the end value, and the number of steps to take inbetween."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tone_frequency = 440 # Hz\n",
    "tone_duration = 4    # seconds\n",
    "\n",
    "samplerate = 48000 # Hz.   Sample period T = 1/samplerate\n",
    "print (\"One digital audio sample lasts just {:.10f} seconds!\".format(1/samplerate))\n",
    "\n",
    "total_samples = tone_duration*samplerate+1\n",
    "print (\"We'll generate {} total samples\".format(total_samples))\n",
    "\n",
    "import numpy as np\n",
    "t = np.linspace(0, tone_duration, total_samples)\n",
    "print(\"Our list of sample times: {}\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's make the actual wave. Recall our formula...\n",
    "\n",
    "$$\n",
    "wave = \\sin(2 * pi * frequency * time)\n",
    "$$\n",
    "\n",
    "numpy helps us again by providing the sine function and the constant Pi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.sin( 2 * np.pi * tone_frequency * t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now created our wave! How can we check it out? Here's a function for listening to the audio, as well as visualizing it in time and frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_audio(audio, Fs, min_sample=0, max_sample=-1):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib import rcParams\n",
    "    rcParams.update({'font.size': 20})\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))\n",
    "    plt.subplots_adjust(hspace=0.37, top=0.95, bottom=0.1)\n",
    "    plot_audio = audio[min_sample:max_sample].squeeze()\n",
    "    ax1.plot(plot_audio, '.', ms='2')\n",
    "    ax1.set_title('Audio Samples')\n",
    "    ax1.set_xlabel('Sample number'); ax1.set_ylabel('Sample amplitude')\n",
    "     \n",
    "    ax2.specgram(plot_audio, NFFT=1024, Fs=Fs, noverlap=256);\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_ylim(10,20000)\n",
    "    ax2.set_title('Spectrogram')\n",
    "    ax2.set_xlabel('Time (sec)'); ax2.set_ylabel('Frequency (Hz)')\n",
    "    \n",
    "    display(Audio(audio.squeeze(), rate=samplerate))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you listen to the audio - does it sound similar to the orchestra clip? How is it different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "view_audio(wave, samplerate, min_sample=0, max_sample=2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting basic signal is a \"chirp\". We can sweep through some frequencies with a the wave, and the spectrogram shows us how the frequency changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_freq = 4  # This might be below human hearing, but it helps to visualize in the plot below\n",
    "end_freq = 8000 # If you go too high the chirp will get painful to listen to towards the end!\n",
    "freq_sweep = np.logspace(np.log2(start_freq), np.log2(end_freq), num=total_samples, base=2)\n",
    "chirp_wave = np.sin( np.cumsum(2 * np.pi * freq_sweep/samplerate))\n",
    "view_audio(chirp_wave, samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Recording Audio</h1>\n",
    "\n",
    "These waves are easy to make in code, but they're pretty boring to listen to. Natural sounds you hear every day are more complex. Let's take a look at sounds recorded from a microphone. There's a Python library for recording and playing audio called sounddevice. First we'll check out the devices available to the computer for recording audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "print(sd.query_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the recording, giving the function info about duration, sample rate, and device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_duration = 5  # seconds\n",
    "my_recording = sd.rec(recording_duration*samplerate, samplerate=samplerate, device=0, channels=1)\n",
    "sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_audio(my_recording, samplerate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the plots of the samples and the spectrogram? Do they look like what you would expect?\n",
    "The _overtones_ you can see in a voice or instrument playing are part of the audio \"fingerprint\" of that particular sound source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Reading Audio From a File</h1>\n",
    "\n",
    "Python can also read sounds from a file. The scipy package helps us out. Below I'm loading a file from my computer, it will not be distributed with the code, but you can try another file on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read as wavread\n",
    "file_Fs, file_wav = wavread('audio/hahn-bach-mono.wav')\n",
    "view_audio(file_wav, Fs=file_Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Changing Audio</h1>\n",
    "\n",
    "Now let's use code to change the way audio sounds.\n",
    "\n",
    "One way to change audio is to filter out parts of the spectrum - we can attenuate some of the frequencies.\n",
    "\n",
    "We'll use the Python library scipy to calculate the filters for us. By changing the parameters of the filter, we can change how the filtered audio sounds. One of the most drastic changes is if we filter out only low frequencies, compared to only high frequencies. Try  swapping between low_filter and high_filter in the lfilter() function below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import iirdesign, lfilter\n",
    "# iirdesign(wp, ws, gpass, gstop, analog=False, ftype='ellip', output='ba')\n",
    "# examples:\n",
    "# lowpass = iirdesign(0.05, 0.1, 1, 60)\n",
    "# highpass = iirdesign(0.1, 0.05, 1, 60)\n",
    "cutoff_frequency = 700 # Hz\n",
    "filt_f_lo = cutoff_frequency/file_Fs*2\n",
    "filt_f_hi = cutoff_frequency/file_Fs*2 + 0.01\n",
    "print(\"Filter parameters: {:.5f} {:.5f}\".format(filt_f_lo, filt_f_hi))\n",
    "low_filter = iirdesign(filt_f_lo, filt_f_hi, 1, 80)\n",
    "high_filter = iirdesign(filt_f_hi, filt_f_lo, 1, 80)\n",
    "\n",
    "filtered_audio = lfilter(*low_filter, file_wav.squeeze())\n",
    "view_audio(filtered_audio, Fs=file_Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Try it out!</h1>\n",
    "\n",
    "What other things can you imagine to manipulate sound?\n",
    "- Add sine waves together - different frequencies, different amplitudes\n",
    "- Change the sample rate when recording\n",
    "- Change the sample rate when playing back\n",
    "- Use the filter functions with different parameters\n",
    "- ....?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>References</h1>\n",
    "- digital audio - https://en.wikipedia.org/wiki/Digital_audio\n",
    "- numpy - https://docs.scipy.org/doc/numpy/reference/routines.html\n",
    "- scipy - https://docs.scipy.org/doc/scipy/reference/index.html\n",
    "- matplotlib pyplot - https://matplotlib.org/api/_as_gen/matplotlib.pyplot.html\n",
    "- sounddevice - https://python-sounddevice.readthedocs.io/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<img></img> <!- this is a dummy img to avoid changes in alignment ->\n",
       "<img class=\"audioSampleSlides\" src=\"img/samples.svg\" onClick=\"nextImg()\">\n",
       "<img class=\"audioSampleSlides\" src=\"img/digital-only.svg\" onClick=\"nextImg()\">\n",
       "<img class=\"audioSampleSlides\" src=\"img/samples-hires.svg\" onClick=\"nextImg()\">\n",
       "<img class=\"audioSampleSlides\" src=\"img/digital-only-hires.svg\" onClick=\"nextImg()\">\n",
       "<script>\n",
       "    var slideIndex=1;\n",
       "    showSlide(slideIndex);\n",
       "    function nextImg() {\n",
       "        showSlide(slideIndex += 1);\n",
       "    }\n",
       "    function showSlide(n) {\n",
       "        var i;\n",
       "        var x = document.getElementsByClassName(\"audioSampleSlides\");\n",
       "        if (n > x.length) {slideIndex = 1};\n",
       "        if (n < 1) {slideIndex = x.length};\n",
       "        for (i = 0; i < x.length; i++) {\n",
       "            x[i].style.display = \"none\"; \n",
       "        }\n",
       "        x[slideIndex-1].style.display = \"block\"; \n",
       "    }\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here's some images to show the impact of sampling rate\n",
    "# the images with more blue dots are double the sampling rate of the others\n",
    "# a higher sampling rate tracks the wave with better fidelity\n",
    "slideshow = \"\"\"\n",
    "<img></img> <!- this is a dummy img to avoid changes in alignment from jupyter ->\n",
    "<img class=\"audioSampleSlides\" src=\"img/samples.svg\" onClick=\"nextImg()\">\n",
    "<img class=\"audioSampleSlides\" src=\"img/digital-only.svg\" onClick=\"nextImg()\">\n",
    "<img class=\"audioSampleSlides\" src=\"img/samples-hires.svg\" onClick=\"nextImg()\">\n",
    "<img class=\"audioSampleSlides\" src=\"img/digital-only-hires.svg\" onClick=\"nextImg()\">\n",
    "<script>\n",
    "    var slideIndex=1;\n",
    "    showSlide(slideIndex);\n",
    "    function nextImg() {\n",
    "        showSlide(slideIndex += 1);\n",
    "    }\n",
    "    function showSlide(n) {\n",
    "        var i;\n",
    "        var x = document.getElementsByClassName(\"audioSampleSlides\");\n",
    "        if (n > x.length) {slideIndex = 1};\n",
    "        if (n < 1) {slideIndex = x.length};\n",
    "        for (i = 0; i < x.length; i++) {\n",
    "            x[i].style.display = \"none\"; \n",
    "        }\n",
    "        x[slideIndex-1].style.display = \"block\"; \n",
    "    }\n",
    "</script>\n",
    "\"\"\"\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(slideshow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACK: use saved file as recorded audio, in case recording doesn't work well\n",
    "from scipy.io.wavfile import read as wavread\n",
    "file_Fs, file_wav = wavread('audio/scale.wav')\n",
    "my_recording = file_wav"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
